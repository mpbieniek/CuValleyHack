{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from glob import glob\n",
    "import random\n",
    "import pickle\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob(\"../../../zadanie2_7z/hmg/joined/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train / val 85% / 15 %\n",
    "random.seed(234)\n",
    "val_split = round(len(data_files)*0.15)\n",
    "val_files = random.sample(data_files, val_split)\n",
    "train_files = [x for x in data_files if x not in val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seq(data_x, data_y, steps):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(data_x) - steps):\n",
    "        end = i + steps\n",
    "        seq_x = data_x[i:end, :]\n",
    "        seq_y = data_y[end, :]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../zadanie2_7z/hmg/joined/data_2021-05-23.csv',\n",
       " '../../../zadanie2_7z/hmg/joined/data_2021-06-06.csv',\n",
       " '../../../zadanie2_7z/hmg/joined/data_2021-05-22.csv',\n",
       " '../../../zadanie2_7z/hmg/joined/data_2021-05-16.csv',\n",
       " '../../../zadanie2_7z/hmg/joined/data_2021-04-23.csv',\n",
       " '../../../zadanie2_7z/hmg/joined/data_2021-04-27.csv']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane = pd.read_csv(train_files[0]).drop(columns = ['Unnamed: 0'])\n",
    "dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "dane_x = dane.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8f9a886b1944329ff03b9c6a1c609e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=33.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 40s 13ms/step - loss: 2333522.7312\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 3124.8970\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 2495.1301\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 2268.0322\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 4008.5493\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 9148.8838\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 2054.7576\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 1778.6422\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1686.2064\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1604.9684\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 32s 12ms/step - loss: 3375.4087\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 2025.9021\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1432.3473\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1180.9258\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 1160.3965\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 4721.0063\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1336.3640\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1301.5222\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1245.9895\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1181.6315\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 36s 13ms/step - loss: 1183.9272\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 1115.5450\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 1101.6143\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 1212.6747\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 4382.6982\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 851.9694\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 996.8574\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 951.7771\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 921.6740\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 889.0040\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 844.0291\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 32s 12ms/step - loss: 861.0746\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 769.4117\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 747.0853\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 754.9633\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 691.6247\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 693.5270\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 661.4349\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 641.7804\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 647.5884\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 601.5482\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 602.3131\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 592.6441\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 621.1483\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 585.4987\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 531.7159\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 548.2548\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 521.8077\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 517.2794\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 510.8122\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 507.2660\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 36s 13ms/step - loss: 486.5764\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 4336.0493\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 1578.9120\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 1210.7969\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 973.6124\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 726.5703\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 651.2242\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 656.0665\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 634.2571\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 603.6826\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 580.6398\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 575.5748\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 581.3958\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 524.9887\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 529.4541\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 520.9378\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 484.8830\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 497.7702\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 450.7694\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 445.2729\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 434.2449\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 420.3748\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 427.1446\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 406.5743\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 406.2841\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 404.6537\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 399.5733\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 392.2589\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 393.8610\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 380.1636\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 373.2535\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 355.7972\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 36s 13ms/step - loss: 364.8574\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 352.6133\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 365.3068\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 345.6286\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 334.7728\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 348.7901\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 331.8462\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 326.3289\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 331.5128\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 322.1328\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 324.5383\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 318.8377\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 302.5269\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 304.7762\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 298.1713\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 298.5789\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 277.0917\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 283.3591\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 279.3081\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 275.7792\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 270.6011\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 264.2063\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 264.8836\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 257.7134\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 250.5893\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 255.9359\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 247.0582\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 237.2345\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 236.2445\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 243.4779\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 219.5946\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 218.0169\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 219.2597\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 214.1934\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 210.2014\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 208.9199\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 201.4306\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 193.7579\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 188.7957\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 198.4171\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 178.0629\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 183.9794\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 32s 12ms/step - loss: 174.1882\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 2080.2537\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 591.5626\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 291.5550\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 267.4323\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 251.3026\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 236.9075\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 32s 12ms/step - loss: 231.7975\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 222.5636\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 223.4655\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 215.9855\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 208.7375\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 208.6433\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 200.4077\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 199.3375\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 193.9243\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 187.9692\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 185.1641\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 179.2991\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 176.9977\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 173.1154\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 32s 12ms/step - loss: 170.4824\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 167.4474\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 162.6890\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 154.1165\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 157.0899\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 150.3226\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 147.9962\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 149.2604\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 142.0172\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 136.1412\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 140.1494\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 135.6758\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 129.5865\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 130.6989\n",
      "Epoch 1/5\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 130.4057\n",
      "Epoch 2/5\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 121.5300\n",
      "Epoch 3/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 120.2633\n",
      "Epoch 4/5\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 130.0252\n",
      "Epoch 5/5\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 122.9814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# exp 1 _ steps = 5\n",
    "\n",
    "n_steps = 5\n",
    "x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "x_features = x.shape[2]\n",
    "y_features = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, x_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(y_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "for file in tqdm(train_files):\n",
    "    dane = pd.read_csv(file).drop(columns = ['Unnamed: 0'])\n",
    "    dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "    dane_x = dane.to_numpy()\n",
    "    x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "    history = model.fit(x, y, epochs = 5, verbose = 1)\n",
    "model.save('../../../zadanie2_7z/hmg/results/exp1/model.h5')\n",
    "with open('../../../zadanie2_7z/hmg/results/exp1/history.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../../../zadanie2_7z/hmg/results/exp2/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d81a91778141d4a32c76879bcc8ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=33.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 37s 13ms/step - loss: 208.4284\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 163.6166\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 158.1809\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 131.8605\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 136.0431\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 142.9281\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 602.3824\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 290.4125\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 246.2331\n",
      "Epoch 1/3\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 177.4799\n",
      "Epoch 2/3\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 130.7615\n",
      "Epoch 3/3\n",
      "1800/1800 [==============================] - 22s 12ms/step - loss: 162.9003\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 473.0236\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 217.4035\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 203.8735\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 99.2551\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 89.1253\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 87.5248\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 109.7309\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 103.0823\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 97.5462\n",
      "Epoch 1/3\n",
      "3600/3600 [==============================] - 44s 12ms/step - loss: 144.2672\n",
      "Epoch 2/3\n",
      "3600/3600 [==============================] - 45s 12ms/step - loss: 120.9644\n",
      "Epoch 3/3\n",
      "3600/3600 [==============================] - 45s 13ms/step - loss: 116.6906\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 316.4325\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 142.1016\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 36s 13ms/step - loss: 132.6930\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 77.3722\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 67.3861\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 69.5603\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 99.1982\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 89.1566\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 88.0580\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 57.3146\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 58.3334\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 59.2978\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 1113.5524\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 772.4376\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 689.8916\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 35s 13ms/step - loss: 186.0794\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 94.8290\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 94.1115\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 124.9859\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 100.0400\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 89.5165\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 81.9186\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 74.1655\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 73.2613\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 181.0694\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 32s 12ms/step - loss: 79.6334\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 32s 12ms/step - loss: 78.3521\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 254.1355\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 234.9136\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 227.6284\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 94.1530\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 83.1169\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 78.7048\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 431.8006\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 264.4136\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 201.5212\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 97.8657\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 69.8243\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 66.0707\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 116.9997\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 34s 12ms/step - loss: 110.4383\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 108.2897\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 34s 13ms/step - loss: 70.2269\n",
      "Epoch 2/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 64.3585\n",
      "Epoch 3/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 63.5683\n",
      "Epoch 1/3\n",
      "2700/2700 [==============================] - 33s 12ms/step - loss: 66.5204\n",
      "Epoch 2/3\n",
      "1616/2700 [================>.............] - ETA: 13s - loss: 64.1756"
     ]
    }
   ],
   "source": [
    "# exp 2 _ steps = 5, simpler model\n",
    "\n",
    "n_steps = 5\n",
    "x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "x_features = x.shape[2]\n",
    "y_features = y.shape[1]\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, x_features)))\n",
    "#model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "#model.add(LSTM(100, activation='relu'))\n",
    "#model.add(Dense(y_features))\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "hist = []\n",
    "for file in tqdm(train_files):\n",
    "    dane = pd.read_csv(file).drop(columns = ['Unnamed: 0'])\n",
    "    dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "    dane_x = dane.to_numpy()\n",
    "    x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "    history = model.fit(x, y, epochs = 3, verbose = 1)\n",
    "    hist.append(history.history)\n",
    "    model.save('../../../zadanie2_7z/hmg/results/exp2/model_last.h5')\n",
    "model.save('../../../zadanie2_7z/hmg/results/exp2/model.h5')\n",
    "with open('../../../zadanie2_7z/hmg/results/exp2/history.txt', 'wb') as file_pi:\n",
    "    pickle.dump(hist, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 1 _ steps = 10\n",
    "\n",
    "n_steps = 10\n",
    "x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "x_features = x.shape[2]\n",
    "y_features = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, x_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(y_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "for file in train_files:\n",
    "    dane = pd.read_csv(train_files[0]).drop(columns = ['Unnamed: 0'])\n",
    "    dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "    dane_x = dane.to_numpy()\n",
    "    x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "    history = model.fit(x, y, epochs = 400, verbose = 0)\n",
    "model.save('../../../zadanie2_7z/hmg/results/exp3/model.h5')\n",
    "with open('../../../zadanie2_7z/hmg/results/exp3/history.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 4 _ steps = 30\n",
    "\n",
    "n_steps = 30\n",
    "x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "x_features = x.shape[2]\n",
    "y_features = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, x_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(y_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "for file in train_files:\n",
    "    dane = pd.read_csv(train_files[0]).drop(columns = ['Unnamed: 0'])\n",
    "    dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "    dane_x = dane.to_numpy()\n",
    "    x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "    history = model.fit(x, y, epochs = 400, verbose = 0)\n",
    "model.save('../../../zadanie2_7z/hmg/results/exp4/model.h5')\n",
    "with open('../../../zadanie2_7z/hmg/results/exp4/history.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 5 _ steps = 60\n",
    "\n",
    "n_steps = 60\n",
    "x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "x_features = x.shape[2]\n",
    "y_features = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, x_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(y_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "for file in train_files:\n",
    "    dane = pd.read_csv(train_files[0]).drop(columns = ['Unnamed: 0'])\n",
    "    dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "    dane_x = dane.to_numpy()\n",
    "    x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "    history = model.fit(x, y, epochs = 400, verbose = 0)\n",
    "model.save('../../../zadanie2_7z/hmg/results/exp5/model.h5')\n",
    "with open('../../../zadanie2_7z/hmg/results/exp5/history.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 6 _ steps = 30\n",
    "\n",
    "n_steps = 30\n",
    "x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "x_features = x.shape[2]\n",
    "y_features = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, x_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(y_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "for file in train_files:\n",
    "    dane = pd.read_csv(train_files[0]).drop(columns = ['Unnamed: 0'])\n",
    "    dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "    dane_x = dane.to_numpy()\n",
    "    x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "    history = model.fit(x, y, epochs = 400, verbose = 0)\n",
    "model.save('../../../zadanie2_7z/hmg/results/exp6/model.h5')\n",
    "with open('../../../zadanie2_7z/hmg/results/exp6/history.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 7 _ steps = 20\n",
    "\n",
    "n_steps = 30\n",
    "x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "x_features = x.shape[2]\n",
    "y_features = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, x_features)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(y_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "for file in train_files:\n",
    "    dane = pd.read_csv(train_files[0]).drop(columns = ['Unnamed: 0'])\n",
    "    dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "    dane_x = dane.to_numpy()\n",
    "    x, y = split_seq(dane_x, dane_y, steps = n_steps)\n",
    "    history = model.fit(x, y, epochs = 500, verbose = 0)\n",
    "model.save('../../../zadanie2_7z/hmg/results/exp7/model.h5')\n",
    "with open('../../../zadanie2_7z/hmg/results/exp7/history.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_y = dane.drop(columns=['001FCx00285_SPPV.PV', '001XXXCALC01.NUM.PV[3]', '001SCx00274_SPPV.PV', '001FCx00241_sppv.pv']).to_numpy()\n",
    "\n",
    "dane_x = dane.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x, input_y = split_seq(dane_x, dane_y, steps = n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(input_x, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3626.4536384230046"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(input_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.33180008e+01, 8.70855033e-01, 1.51373994e+00, 7.21114254e+00,\n",
       "       7.29695272e+00, 6.44669533e+00, 1.14000000e+02, 1.00000000e+01,\n",
       "       3.00000000e+00, 3.49889832e+02, 3.12519609e+04, 9.90577539e+03,\n",
       "       2.99000000e+02, 8.68000031e+00, 1.12200003e+01, 2.27999997e+00,\n",
       "       6.30000000e+01, 1.37000000e+03, 1.36572247e+01, 9.36909103e+00,\n",
       "       1.31000000e+03, 2.46942893e-01])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.1546745e+01,  7.4828500e-01, -6.0043967e-01,  3.5830178e+00,\n",
       "        5.5966163e+00,  1.3751291e+01,  1.1395613e+02,  1.1289093e+01,\n",
       "        9.4705683e-01,  3.4296664e+02,  3.1261605e+04,  9.8865430e+03,\n",
       "        2.9139093e+02,  1.1230208e+01,  8.0696602e+00,  6.9680538e+00,\n",
       "        6.8245575e+01,  1.3641378e+03,  9.3218222e+00,  8.8075914e+00,\n",
       "        1.2924592e+03,  4.1678696e+00], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
